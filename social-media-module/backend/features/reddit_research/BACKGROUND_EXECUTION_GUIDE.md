# Reddit Research Background Execution Guide

## ğŸ¯ **The Problem Solved**

**Before**: Running Reddit scrapers blocked your terminal and prevented you from using Cursor
**Now**: Run scrapers in background while continuing to use Cursor normally!

## ğŸš€ **Quick Start Commands**

### Option 1: Use the Background Runner Script (Recommended)

```bash
# Navigate to the script location
cd /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research

# Run simple scraper in background
./run_reddit_background.sh simple

# Run configurable scraper in background
./run_reddit_background.sh configurable

# Run with custom parameters
./run_reddit_background.sh custom --posts 5 --comments 30 --subreddits artificial MachineLearning

# Check what's running
./run_reddit_background.sh status

# Monitor progress
./run_reddit_background.sh logs

# Stop all scrapers
./run_reddit_background.sh stop
```

### Option 2: Manual Background Execution

```bash
# Simple scraper in background
cd /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend && source venv/bin/activate && nohup python features/reddit_research/cli_reddit_scraper_simple.py > reddit_simple.log 2>&1 &

# Configurable scraper in background
cd /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend && source venv/bin/activate && nohup python features/reddit_research/cli_reddit_scraper_configurable.py --posts 4 --comments 20 > reddit_config.log 2>&1 &
```

## ğŸ“‹ **Background Runner Features**

### Available Commands

| Command | Description | Example |
|---------|-------------|---------|
| `simple` | Run simple scraper with defaults | `./run_reddit_background.sh simple` |
| `configurable` | Run configurable scraper | `./run_reddit_background.sh configurable` |
| `custom` | Run with custom parameters | `./run_reddit_background.sh custom --posts 3 --comments 50` |
| `status` | Check running processes | `./run_reddit_background.sh status` |
| `logs` | Monitor latest log file | `./run_reddit_background.sh logs` |
| `stop` | Stop all Reddit scrapers | `./run_reddit_background.sh stop` |

### What Happens When You Run in Background

1. **âœ… Terminal Returns Immediately** - You can continue using Cursor
2. **âœ… Process Persists** - Continues even if you close terminal
3. **âœ… Logging** - All output saved to timestamped log files
4. **âœ… Process Tracking** - PID files for easy management
5. **âœ… Multiple Scrapers** - Can run several simultaneously

## ğŸ” **Monitoring Your Background Scrapers**

### Check What's Running
```bash
# Using the background runner
./run_reddit_background.sh status

# Manual check
ps aux | grep -E "python.*reddit"
```

### Monitor Progress in Real-Time
```bash
# Using the background runner (monitors latest log)
./run_reddit_background.sh logs

# Manual monitoring
tail -f /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/logs/reddit_*.log
```

### Check Results
```bash
# List result files
ls -la /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research/results/

# View latest results
cat /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research/results/$(ls -t *.json | head -1)
```

## ğŸ›ï¸ **Configuration Options**

### Simple Scraper (Default Settings)
- **Posts per subreddit**: 6
- **Comments per post**: 15
- **Subreddits**: artificial, productivity, Entrepreneur

### Configurable Scraper Examples

```bash
# Deep dive with many comments
./run_reddit_background.sh custom --posts 3 --comments 50 --subreddits artificial

# Broad survey with many posts
./run_reddit_background.sh custom --posts 10 --comments 10 --subreddits artificial productivity SaaS Entrepreneur

# Focus on specific topic
./run_reddit_background.sh custom --posts 5 --comments 25 --query "business automation tools 2025" --subreddits productivity SaaS

# AI-focused research
./run_reddit_background.sh custom --posts 4 --comments 30 --subreddits artificial MachineLearning datascience
```

## ğŸ“ **File Locations**

### Scripts
```
/Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research/
â”œâ”€â”€ run_reddit_background.sh              # Background runner script
â”œâ”€â”€ cli_reddit_scraper_simple.py          # Simple scraper
â”œâ”€â”€ cli_reddit_scraper_configurable.py    # Configurable scraper
â””â”€â”€ BACKGROUND_EXECUTION_GUIDE.md         # This guide
```

### Logs and Results
```
/Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ reddit_simple_20250116_143022.log     # Timestamped log files
â”‚   â”œâ”€â”€ reddit_configurable_20250116_143155.log
â”‚   â”œâ”€â”€ reddit_simple.pid                     # Process ID files
â”‚   â””â”€â”€ reddit_configurable.pid
â””â”€â”€ features/reddit_research/results/
    â”œâ”€â”€ simple_reddit_research_20250116_143045.json
    â””â”€â”€ configurable_reddit_research_20250116_143201.json
```

## ğŸ”§ **Troubleshooting**

### Common Issues and Solutions

#### "Virtual environment not found"
```bash
# Create and setup virtual environment
cd /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### "Permission denied"
```bash
# Make script executable
chmod +x /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research/run_reddit_background.sh
```

#### "Process not stopping"
```bash
# Force stop all Reddit processes
pkill -f "python.*reddit"

# Or find and kill specific PID
ps aux | grep -E "python.*reddit"
kill -9 <PID>
```

#### "No log output"
```bash
# Check if process is actually running
./run_reddit_background.sh status

# Check log file permissions
ls -la /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/logs/
```

## ğŸ’¡ **Pro Tips**

### 1. **Multiple Scrapers Simultaneously**
```bash
# Run different configurations at the same time
./run_reddit_background.sh custom --posts 3 --comments 50 --subreddits artificial &
./run_reddit_background.sh custom --posts 5 --comments 20 --subreddits productivity &
./run_reddit_background.sh custom --posts 4 --comments 30 --subreddits Entrepreneur &
```

### 2. **Monitor Multiple Logs**
```bash
# Monitor all Reddit logs simultaneously
tail -f /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/logs/reddit_*.log
```

### 3. **Scheduled Execution**
```bash
# Add to crontab for scheduled execution
# Run every 6 hours
0 */6 * * * /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research/run_reddit_background.sh simple
```

### 4. **Resource Management**
- **CPU Usage**: Each scraper uses ~10-20% CPU during AI analysis
- **Memory**: ~200-500MB per scraper process
- **Network**: Moderate API calls (respects Reddit rate limits)
- **Disk**: Log files ~1-5MB, result files ~1-10MB

### 5. **Best Practices**
- **Start with simple scraper** to test everything works
- **Monitor first few runs** to understand timing
- **Use custom parameters** for specific research needs
- **Stop scrapers** when not needed to save resources
- **Check results regularly** to see what insights are captured

## ğŸ¯ **Integration with Cursor Workflow**

### Typical Workflow
1. **Start scraper in background**: `./run_reddit_background.sh simple`
2. **Continue using Cursor normally** - ask questions, write code, etc.
3. **Periodically check progress**: `./run_reddit_background.sh status`
4. **Monitor when needed**: `./run_reddit_background.sh logs`
5. **Review results when complete**: Check results directory
6. **Stop when done**: `./run_reddit_background.sh stop`

### Benefits for Development
- âœ… **Uninterrupted Cursor usage** - Ask questions anytime
- âœ… **Parallel processing** - Scrape data while developing
- âœ… **Continuous insights** - Regular data collection
- âœ… **No context switching** - Stay focused on development
- âœ… **Resource efficient** - Background processes don't block UI

---

## ğŸš€ **Quick Reference**

```bash
# Essential commands (copy-paste ready)

# Start simple scraper
cd /Users/galenoakes/Development/Sentigen-Social/social-media-module/backend/features/reddit_research && ./run_reddit_background.sh simple

# Check status
./run_reddit_background.sh status

# Monitor progress
./run_reddit_background.sh logs

# Stop all scrapers
./run_reddit_background.sh stop

# Custom deep research
./run_reddit_background.sh custom --posts 3 --comments 50 --subreddits artificial
```

**Now you can run Reddit scrapers in the background while continuing to use Cursor normally!** ğŸ‰
